## 제5장. 안정 해시 설계 (Consistent Hashing)

> 서버가 수시로 늘고 줄어드는 환경에서도 전체 키를 재배치하지 않고 영향 범위를 `k/n` 수준으로 제한하는 분산 해시 기법

### 5.1 왜 안정 해시인가?
- **고전적 해시 한계**: `hash(key) % N` 은 N 변동 시 거의 모든 키가 이동 → 캐시 미스, 네트워크 트래픽 폭증
- **안정 해시 정의**: 평균적으로 전체 키 중 `k/n` 개만 재배치되도록 고안된 해시 기법
- **대표 활용 사례**: Dynamo, Cassandra, Akamai CDN, Consistent Hash 기반 L4/L7 로드 밸런서

### 5.2 해시 공간과 링 모델
1. **해시 공간(Hash Space)**: SHA-1, MurmurHash 등 160bit 해시 출력 범위(`0 ~ 2^160-1`)
2. **해시 링(Hash Ring)**: 해시 공간의 양 끝을 연결한 원형 좌표계
3. **노드/키 배치**
   - 서버 식별자(IP, 토큰 등)에 해시를 적용해 링 위 위치 결정
   - 키 또한 같은 해시 함수로 좌표 계산
   - 키 위치에서 **시계 방향으로 최초로 만나는 서버**가 책임 노드

```
[해시 링 개념도]
키 위치 ──▶ (시계방향) ──▶ 최초 서버가 키 저장
```

### 5.3 요청 처리 흐름
1. 클라이언트가 `put(key, value)` 요청
2. 조정자가 키 해시 계산 후 책임 노드를 선정
3. 다중화 설정 시 링을 따라 `N`개의 후속 노드에 복제
4. 읽기 시 `R`개의 응답을 모아 최신 버전을 결정(쿼럼)

### 5.4 구현 시 주요 이슈와 해결책

| 문제 | 증상 | 해결 전략 |
| --- | --- | --- |
| 파티션 크기 불균등 | 특정 노드가 과도한 구간 담당 → 핫스팟 | 가상 노드(VNode) 추가, 토큰 자동 재조정, 주기적 리밸런싱 |
| 키 분포 불균등 | 해시 편향/키 패턴으로 구간 집중 | 강한 해시(Murmur, Jump Hash), 키 prefix 샤딩, VNode 수 확장 |

#### 가상 노드(VNode) 운용 팁
- 물리 서버 하나가 수십~수백 개 토큰을 소유
- 장애 시 VNode 단위로 위임(handoff)하여 빠르게 책임 전환 가능
- 토큰 수를 늘려 데이터 이동량을 세분화하고 throttle 제어

#### 운영 체크리스트
- **토큰 자동화**: 신규 노드 합류 시 토큰 계산·배포 자동화
- **모니터링**: 노드별 파티션 크기, 키 개수, 데이터 이동 속도
- **데이터 재배치 전략**: 백그라운드 스레드, 외부 버퍼(S3 등) 활용해 서비스 영향 최소화

---

## 제6장. 키-값 저장소 설계 (Key-Value Store)

> **핵심 메시지**  
> 키-값 저장소는 (1) 키/값 기반의 단순 데이터 모델 위에, (2) CAP 트레이드오프와 정족수 합의를 적용해, (3) 높은 규모 확장성과 조정 가능한 일관성을 제공하는 분산 저장소이다.

### 6.0 키-값 저장소 개요
- **데이터 모델**:  
  - **키(key)**: 레코드를 식별하는 고유 ID (예: `user_id`, `session_token`)  
  - **값(value)**: 해당 키에 매달린 데이터 blob (JSON, 바이너리, 문자열 등)  
- **특징**
  - 매우 단순한 API: `get(key)`, `put(key, value)`, `delete(key)`  
  - **수평 확장성**: 샤딩 + 복제를 통해 서버 수를 자유롭게 늘리며 TB~PB 단위 데이터 처리  
  - **튜너블 일관성**: 시스템 요구사항에 따라 강한/약한/최종 일관성 선택 가능

---

### 6.1 CAP 정리와 시스템 유형

1. **CAP 정리 요약**
   - **C(Consistency)**: 모든 노드에서 같은 시점에 같은 데이터를 본다.
   - **A(Availability)**: 모든 요청에 대해 항상 응답(성공 또는 실패)을 돌려준다.
   - **P(Partition tolerance)**: 네트워크가 분할되어도 시스템이 일부라도 계속 동작한다.
2. **분산 시스템의 현실**
   - 네트워크 분할(Partition)은 **피할 수 없으므로(P 필수)**, 실질적으로는 **C와 A 중 무엇을 더 우선할지 선택**하는 문제로 귀결된다.

| 유형 | 보장 | 포기 | 예시 |
| --- | --- | --- | --- |
| **CP** | 일관성 + 파티션 감내 | 일부 요청의 가용성 | HBase, ZooKeeper |
| **AP** | 가용성 + 파티션 감내 | 즉시 일관성 | Cassandra, Dynamo |
| **CA** | (이론상) 일관성 + 가용성 | 파티션 감내 | 단일 머신 RDB 등, 분산이라 보기 어려움 |

- 설계 시 질문: “이 시스템은 **잠깐의 오류/지연** vs **오래된 데이터** 중 어느 쪽을 더 감수할 수 있는가?”

---

### 6.2 데이터 복제와 정족수 합의 (N, R, W)

키-값 저장소는 높은 가용성과 내구성을 위해 데이터를 여러 노드에 복제한다.

#### 6.2.1 복제 기본 개념
- **N (Replication Factor)**: 같은 데이터를 저장하는 복제본 수  
- 노드 장애/네트워크 이슈가 있어도 읽기/쓰기가 가능하도록 보장

#### 6.2.2 정족수 합의 (Quorum Consensus)
- **W (쓰기 정족수)**: 쓰기가 성공했다고 간주되기 위해 **성공 응답을 받아야 하는 최소 노드 수**
- **R (읽기 정족수)**: 읽기가 성공했다고 간주되기 위해 **응답을 받아야 하는 최소 노드 수**
- **강한 일관성 조건**:  
  - `W + R > N` 이면, 읽기/쓰기 집합이 항상 **하나 이상의 공통 노드**를 공유  
  - → 최소 한 노드는 **가장 최신 버전**을 가지고 있으므로, 읽기가 최신 데이터를 보게 된다.

| 워크로드 | 파라미터 예시 | 특징 |
| --- | --- | --- |
| 읽기 위주 서비스 | `N=3, W=1, R=2` | 쓰기는 빠르고, 읽기는 쿼럼으로 최신성 확보 |
| 쓰기 위주 서비스 | `N=5, W=3, R=1` | 쓰기 안정성·내구성 우선, 읽기 지연 최소화 |
| 강한 일관성 근접 | `N=3, W=2, R=2` | 지연은 늘지만 최신 데이터 제공 가능성↑ |

#### 6.2.3 일관성 모델 (Consistency Model)
- **강한 일관성(Strong Consistency)**: 모든 읽기가 가장 최근 쓰기를 반영
- **약한 일관성(Weak Consistency)**: 일부 읽기는 최신 상태가 아닐 수 있음
- **최종 일관성(Eventual Consistency)**: 일정 시간이 지나면 결국 모든 복제본이 같은 상태로 수렴  
  - Dynamo, Cassandra, DynamoDB 등이 채택하는 모델

---

### 6.3 비일관성 해소 기법 (Inconsistency Resolution)

복제를 하면 가용성은 올라가지만, 네트워크 지연·장애로 인해 복제본 간 데이터가 다른 상태가 될 수 있다.
이를 해결하기 위한 대표적인 기법들은 다음과 같다.

1. **데이터 버전 관리 (Data Versioning)**
   - 데이터를 변경할 때마다 **새로운 버전**을 생성하고, 기존 버전은 불변(immutable)으로 유지
   - 여러 버전을 동시에 보관하여 **충돌 분석/롤백**을 쉽게 함
2. **벡터 시계(Vector Clock)**
   - 각 데이터 항목에 대해 `(노드ID, version_counter)` 쌍들의 집합을 저장 (예: `D([S1,v1], [S2,v2], ...)`)
   - 이를 통해 두 버전 간의 관계를 판단:
     - 한 버전이 다른 버전보다 **명백히 최신**인지(선행/후행 관계)
     - 서로 다른 타임라인에서 독립적으로 수정된 **충돌 상태**인지
3. **Read Repair**
   - 클라이언트가 읽기할 때, 여러 복제본에서 데이터를 가져와 비교
   - 최신 버전을 기준으로 오래된 복제본을 **백그라운드로 업데이트**
4. **Hinted Handoff (단서 후 위탁)**
   - 임시 장애(예: `s2` 다운) 시, 그 노드가 받아야 할 쓰기를 이웃 노드(예: `s3`)가 **대신 저장**
   - `s3`는 “힌트(hint)”를 기록해 두었다가 `s2`가 복구되면 변경분을 전달
5. **Anti-Entropy (Merkle Tree 기반 동기화)**
   - 장기적인 데이터 불일치를 해소하기 위해 **머클 트리(Merkle Tree)** 사용
   - 각 노드의 데이터 집합을 트리 구조의 해시로 요약하고, 루트 해시를 비교
   - 해시가 다른 서브트리만 내려가면서 세부 비교 → **불일치 버킷만 동기화**하여 네트워크 비용 절감

---

### 6.4 시스템 아키텍처와 장애 처리

키-값 저장소는 **완전 분산(decentralized)** 구조를 채택하여 단일 실패 지점(SPOF)이 없도록 설계한다.

#### 6.4.1 주요 구성 요소
1. **클라이언트**
   - 단순 API: `get(key)`, `put(key, value)`, `delete(key)` 호출
2. **조정자(Coordinator)**
   - 클라이언트와 노드 사이에서 **프록시 역할**
   - 주어진 키에 대해 읽기/쓰기를 수행할 **N개의 노드 선택**, `R/W` 정족수 관리
3. **노드(Node)**
   - 안정 해시 링 위에 분포
   - 클라이언트 API 처리, 장애 감지, 데이터 충돌 해소, 복제, 저장소 엔진 등 핵심 기능 수행

#### 6.4.2 분산 장애 감지 (Decentralized Failure Detection)
- **가십 프로토콜(Gossip Protocol)** 사용
  - 각 노드는 주기적으로 일부 다른 노드와 상태 정보를 교환
  - 노드마다 **멤버 목록(membership list)** 과 `heartbeat counter`를 유지
  - 특정 노드의 heartbeat가 일정 시간 동안 갱신되지 않으면 **장애**로 간주

#### 6.4.3 요청 흐름 (쓰기/읽기 경로)
1. 클라이언트 → 조정자: `put(key, value)` 또는 `get(key)`
2. 조정자 → 링 탐색: 책임 노드 집합 도출(안정 해시 이용)
3. 쓰기: N개 노드에 병렬 전송 후, `W`개의 ACK 수집 시 성공으로 간주
4. 읽기: N개 중 최소 `R`개의 응답 수집 → 버전 비교 후 최신 데이터 반환  
   필요 시 read repair 수행

#### 6.4.4 임시·영구 장애 처리
1. **Hinted Handoff (단서 후 위탁)**  
   - 일시적 장애 노드(예: `s2`) 대신, 다른 건강한 노드(예: `s3`)가 해당 쓰기 요청을 임시로 수신  
   - `s3`는 “힌트(hint)” 메타데이터를 남겨 두었다가 `s2`가 복구되면 최신 데이터를 전달  
   - 복구 시간 동안 쓰기 가용성을 유지하면서, 복귀 후 빠르게 일관성을 되찾을 수 있음
2. **Anti-Entropy (Merkle Tree 기반 동기화)**  
   - 영구 장애 또는 장기적인 데이터 불일치에 대응하기 위해 **머클 트리(Merkle Tree)** 사용  
   - 각 노드는 보유 데이터의 해시로 구성된 트리를 유지하며, 루트 해시를 서로 비교  
   - 루트가 다르면 하위 노드로 내려가며 불일치 구간만 식별 → 해당 버킷만 동기화하여 전송량 최소화  
   - 주기적 실행으로 복제본 간 최종 일관성을 보장

---

### 6.5 저장소 엔진 (Storage Engine) 예: Cassandra 스타일

키-값 노드 내부에서는 일반적으로 **로그 구조 저장소(LSM-Tree)** 기반 엔진을 사용한다.

#### 6.5.1 쓰기 경로
1. 모든 쓰기는 먼저 **커밋 로그(commit log)** 에 순차적으로 기록 → 장애 시 복구용
2. 동시에 메모리 상의 구조(예: memtable)에 기록
3. 메모리가 가득 차면 디스크에 **SSTable(Sorted-String Table)** 형태로 flush  
   - SSTable은 키 기준으로 정렬된 불변의 파일

#### 6.5.2 읽기 경로
1. 먼저 메모리에서 키 검색
2. 없으면 Bloom Filter, 인덱스를 이용해 어느 SSTable에 존재할지 판단
3. 필요한 SSTable에서 데이터를 가져와 클라이언트에게 반환

#### 6.5.3 운영 시 고려 사항
- compaction 정책(크기 기반, 레벨 기반 등)에 따라 **쓰기/읽기 성능·디스크 사용량**이 달라짐
- 커밋 로그와 SSTable의 위치를 분리(I/O 분리)해 성능 향상 가능

---