# 📒 5장 - 안정 해시 설계

- 수평적 규모 확장을 위해서는 요청 또는 데이터를 서버에 균등하게 나누는 것이 중요하다.

→ 이를 위해 안정 해시를 설계

## ✅ 해시 키 재배치(rebase) 문제

serverIndex = hash % 4

서버 풀의 크기가 고정되어 있고, 데이터 분포가 균등할때는 잘 작동한다.

but. 서버가 늘어나거나 기존 서버가 삭제 된다면 문제가 생긴다.

→ 키에 대한 해시값은 변하지 않지만 서버 인덱스는 서버 크기가 달라지기에 달라진다.

즉 키가 재분재 되어 대부분 캐시 클라이언트가 데이터가 없는 엉뚱한 서버에 접속한다.

→ 대규모 케시 미스 문제 발생

어떻게 해결하는가?

→ 안정 해시

## ✅ 안정 해시

해시 테이블 크기가 조정될때 평균적으로 k/n 개의 키만 재배치 하는 해시 기술

k: 키의 개수

n: 슬롯의 개수

## ✅ 해시 공간과 해시 링

✏️동작 원리

- 해시 함수: SHA-1 사용한다고 가정
    - 출력 범위: x0,x1…..xn
    - 해시 공간 범위: 0~ 2^160 -1

![alt text](image.png)

## ✅ 해시 서버
해시 함수 f 를 사용하면 서버 ip나 이름으 링 위의 어떤 위치에 대응시킬 수 있다.

## ✅ 해시 키
![alt text](image-1.png)


## ✅ 서버 조회
어떤 키가 저장된 서버는 해당 키의 위치로부터 시계 방향으로 링을 탐색해 나가면서 만나는 첫번째 서버이다

![alt text](image-2.png)

## ✅ 서버 추가
서버를 추가하더라고 가운데 키 일부만 재배치 하면 된다.
![alt text](image-3.png)

## ✅ 서버 제거
키 일부만 재배치
![alt text](image-4.png)

## ✅ 기존 구현법의 문제점
1) 서버와 키를 균등 분포 해시 함수를 사용해 해시 링에 재배치
2) 키의 위치에서 링을 시계 방향으로 탐색하다 처음으로 만나는 서버에 키가 저장

-> 두가지 문제점 존재

1. 서버가 추가, 삭제될때 상황을 감안하면 파티션의 크기를 균등하게 유지하는 것이 불가능
- 파티션: 인접한 서버 사이의 해시 공간

![alt text](image-5.png)

### -> 어떻게 해결하는가? 가상 노드 or 복제 기법

## ✅ 가상 노드
- 가상노드: 실제 노드 또는 서버를 가리키는 노드
- 하나의 서버는 링 위의 여러 가상 노드를 가질 수 있다.
![](image-6.png)

가상 노드의 개수 ⬆️ -> 키의 분포 균등
-> 표준 편차가 작아져서 데이터가 고르게 분포되기 때문
- 표준 편차: 데이터가 어떻게 퍼져 나갔는지 보이는 척도
- 100~200개의 가상 노드를 사용했을 경우 표준 편차의 값은 평균 5% 사이라고 한다.
- 가상 노드를 늘리면 표준 편차의 값은 더 떨어지나, 가상 노드 데이터를 저장할 공간은 더 많이 필요하게 된다.

## ✅ 재배치할 키 결정
어느 범위의 키들을 재배치 해야하는가.

## ✅ 안정 해시의 이점
- 서버가 추가, 삭데 될때 재배치 되는 키의 수 최소화
- 데이터가 보다 균등하게 분포하게 되므로 수평적 규모 확장에 유리
- 핫스팟 키 문제를 줄인다.

# 📒 6장 - 키-값 저장소 설계
- 키 값 저장소: 키 값 데이터 베이스라고도 불리는 비 관계형 데이터 베이스
- 고유한 식별자를 키로 가져야 한다.
- 키와 값 사이의 연결 관계를 키 값 쌍이라고 부른다.

- put(key, value): 저장
- get(key): 조회

```
- 키-값 쌍의 크기는 10KB이하이다.
- 큰 데이터를 저장할 수 있어야 한다.
- 높은 가용성을 제공해야 한다. 따라서 시스템은 설사 장애가 있더라도 빨리 응답해야 한다.
- 높은 규모 확장성을 제공해야 한다. 따라서 트래픽 양에 따라 자동적으로 
서버 증설/삭제가 이루어져야 한다.
- 데이터 일관성 수준은 조정이 가능해야 한다.
- 응답 지연시간이 짧아야 한다.
```

## ✅ 단일 서버 키-값 저장소
- 빠른 속도 보장하지만 모든 데이터를 메모리 안에 두는 것은 불가능
-> 해결법: 데이터 압축, 자주 쓰이는 데이터는 메모리에, 나머지는 디스크에 저장

## ✅ 분산 키-값 저장소(= 분산 해시 테이블)

### cap 정리
 데이터 일관성, 가용성, 파티션 감내 라는 세 가지 요구사항을 동시에 만족하는 분산 시스템을 설계하는 것은 불가능하다는 정리

- 데이터 일관성(C)
    -   분산 시스템에 접속하는 모든 클라이언트는 어떤 노드에 접속했느냐와 관계 없이 언제나 같은 데이터를 보게 되어야 한다.

- 가용성(A)
    -  분산 시스템에 접속하는 클라이언트는 일부 노드에 장애가 발생하더라도 항상 응답을 받을 수 있어야 한다.

- 파티션 감내(P)
    - 파티션은 두 노드 사이에 통신 장애가 발생하였음을 의미한다.
즉, 파티션 감내는 네트워크에 파티션이 생기더라도 시스템이 계속 동작해야 한다는 것을 뜻한다.

- CP시스템
- AP시스템
- CA시스템
* 통상 네트워크 장애는 피할 수 없는 것으로 여겨지기 때문에 분산시스템은 반드시 파티션 문제를 감내할 수 있도록 설계되어야 한다.

    -> 따라서 CA시스템은 실질 존재하지 않는다.


분산 시스템에서 대부분 데이터는 여러 노드에 복제되어 보관
 ### 이상적 상태
 : 네트워크가 파티견되는 상황이 절대로 안일어날 것
 n1에 기록된 데이터는 n2, n3에 복제 -> 데이터 일관성과 가용성 만족

![alt text](image-7.png)

### 실세계
파티션 문제는 불가피함.
파티션 문제 발생시, 일관성과 가용성 사이에서 하나를 선택해야한다.
![alt text](image-8.png)

- 가용성 대신 일관성을 선택(CP시스템) 
    - 세 서버 사이에 생길 수 있는 데이터 불일치 문제를 피하기 위해 n1과 n2에 대해 쓰기 연산을 중단시켜야 하는데, 그렇게 하면 가용성이 깨진다.
    - 만약에 일관성이 깨질 수 있는 상황이 발생하면 이런 시스템인 상황이 해결될 때 까지는 오류를 반환해야 한다.

- 인관성 대신 가용성을 선택(AP시스템) 
    - 낡은 데이터를 반환할 위험이 있다고 해도 계속 읽기 연산을 허용해야 한다.
    - 그리고 n1과 n2에서는 계속 쓰기 연산을 허용할 것이고, 파티션 문제가 해결된 후에 새 데이터를 n3에 전송할 것이다.



## ✅ 시스템 컴포넌트

### 데이터 파티션
- 데이터를 여러 서버에 고르게 분산할 수 있는가
- 노드가 추가되거나 삭제될 때 데이터의 이동을 최소화 할 수 있는가
- 장점
    - 규모 확장 자동화
    - 다양성

### 데이터 다중화
- 높은 가용성과 안정성을 확보하기 위해서는 데이터를 N개 서버에 비동기적으로 다중화할 필요가 있다.
- 여기서 N은 튜닝 가능한 값이다.
![alt text](image-9.png)

- 가상 노드를 사용한다면 위와 같이 선택한 N개의 노드가 대응될 실제 물리 서버의 개수가 N보다 작아질 수 있다.
    - 이를 해결하기 위해서는 같은 물리 서버를 중복 선택하지 않도록 해야 한다.

- 같은 데이터 센터에 속한 노드는 정전, 네트워크 이슈 등의 문제를 동시에 겪을 가능성이 있다.

-> 데이터의 사본은 다른 센터의 서버에 보관하고, 센터들은 고속 네트워크로 연결한다.

## 데이터 일관성
- 여러 노드에 다중화된 데이터는 적절히 동기화 되어야한다
- 정족수 합의 프로토콜을 사용해 일관성 보장

~~~
- N=사본 개수
- W=쓰기 연산에 대한 정족수
    쓰기 연산이 성공한 것으로 간주되려면 적어도 W개의 서버로부터 쓰기 연산이 성공했다는 응답을 받아야 한다.
- R=읽기 연산에 대한 정족수
    읽기 연산이 성공한 것으로 간주되려면 적어도 R개의 서버로부터 응답을 받아야 한다.
~~~
![alt text](image-10.png)

W+N>N: 강한 일관성이 보장

일관성을 보증할 최신 데이터를 가진 노드가 최소 하나는 겹칠 것이기 때문이다.

~~~
- R=1, W=N : 빠른 읽기 연산에 최적화된 시스템
- W=1, R=N : 빠른 쓰기 연산에 최적화된 시스템
- W+R>N : 강한 일관성 보장
- W+R<=N : 강한 일관성의 보장이 없다.
~~~
요구되는 일관성 수준에 따라 조정하면 된다.

## 일관성 모델
- 강한 일관성:
    - 모든 읽기 연산은 가장 최근에 갱신된 결과를 반환한다.
다시 말해서 클라이언트는 절대로 낡은 데이터를 보지 못한다.

- 약한 일관성
    - 읽기 연산은 가장 최근에 갱신된 결과를 반환하지 못할 수 있다.

- 최종 일관성
    - 약한 일관성의 한 형태로, 갱신 결과가 결국에는 모든 사본에 반영(==동기화) 되는 모델이다.

### 비 일관성 해소 기법 : 데이터 버저닝
데이터를 다중화하면 가용성은 높아지지만 사본 간 일관성이 깨질 가능성이 높다.

-> 해결법: 버저닝, 벡터 시계

- 버저닝:  데이터를 변경할 때마다 해당 데이터의 새로운 버전을 만드는 것
- 벡터 시계:
    - [서버, 버전]의 순서쌍을 데이터에 매단 것이다.
    - 어떤 버전이 선행 버전인지, 후행 버전인지, 아니면 다른 버전과 충돌이 있는지 판별하는 데에 쓰인다.
    - D([S1, v1], [S2, v2] ... [Sn, vn])
        - D는 데이터, vi는 카운터, si는 서버 번호
        - [Si, vi]가 있다면 vi를 증가시킨다.
        - 그렇지 않으면 새 항목[Si, 1]를 만든다.

- 단점
    - 충돌 감지 및 해소 로직이 클라이언트에 들어가야 하므로, 클라이언트 구현이 복잡해진다.
     - [서버:버전] 의 순서쌍 개수가 굉장히 빨리 늘어난다


### 장애 감지
두대 이상 서버에서 장애를 감지해야 장애가 발생했다고 판단한다.
![alt text](image-12.png)
- 모든 노드 사이에 멀티캐스팅 채널 구축하는 것이 가장 쉬움
-> 하지만 노드가 많으면 비효율적

- 가십 프로토콜
    - 각 노드는 멤버십 목록을 유지한다. 멤버십 목록은 각 멤버 Id와 그 박동 카운터 쌍의 목록이다.
    - 각 노드는 주기적으로 자신의 박동 카운터를 증가시킨다.
    - 각 노드는 무작위로 선정된 노드들에게 주기적으로 자기 박동 카운터 목록을 보낸다.
    - 박동 카운터 목록을 받은 노드는 멤버십 목록을 최신 값으로 갱신한다
    - 어떤 멤버의 박동 카운터 값이 지정된 시간 동안 갱신되지 않으면 해당 멤버는 장애 상태인 것으로 간주한다.
    ![](image-13.png)

### 일시적 장애 처리
- 엄격한 정족수 접근법 -> 읽기와 쓰기 연산을 금지

- 느슨한 정족수 접근법 -> 이 조건을 완화하여 가용성을 높인다

### 영구 장애 처리
머클트리 사용
- 머클트리:
    - 해시 트리라고도 불리며 각 노드에 그 자식 노드들에 보관된 값의 해시, 또는 자식 노드들의 레이블로부터 계산된 해시 값을 레이블로 붙여두든 트리

### 데이터 센터 장애 처리
정전, 네트워크 장애, 자연재해
- 여러 데이터 센터에 다중화하는 것이 중요

## ✅ 시스템 아키텍쳐 다이어그램
- 클라이언트: 키-값 저장소가 제공하는 두 가지 단순한 API, 즉 get(key) 및 put(key, value)와 통신
- 중재자: 클라이언트에게 키-값 저장소에 대한 프락시 역할
- 노드: 안정 해시의 해시 링 위에 분포
- 노드를 자동으로 추가/삭제할 수 있도록 시스템은 완전히 분산된다.
- 데이터는 여러 노드에 다중화된다.
- 모든 노드가 같은 책임을 지므로, SPOF(Single Point of Failure)는 존재하지 않는다.

## 쓰기 경로
![alt text](image-14.png)
1. 쓰기 요청이 커밋 로그 파일에 기록
2. 데이터가 메모리 캐시에 기록
3. 메모리 캐시가 가득차거나 사전에 정의된 어떤 임계치에 도달하면 데이터는 디스크에 있는 SSTable에 기록
    - SSTable: Sorted-String Table의 약어, <키, 값>의 순서쌍을 정렬된 리스트 형태로 관리하는 테이블

## 읽기 경로
![alt text](image-15.png)

1. 데이터가 메모리 캐시에 있는지 부터 확인
2. 없는 경우 디스크에서 가져옴

- 블룸 필터
![alt text](image-16.png)
1. 데이터가 메모리 있는지 검사-> 없으면 2
2. 데이터가 메모리에 없으므로 블룸 필터를 검사
3. 블룸 필터를 통해 어떤 SSTable에 키가 보관되어 있는지 확인
4. SSTable에서 데이터를 가져옴
5. 해당 데이터를 클라이언트에 반환

## ✅ 요약

| 목표/문제                         | 기술                                                             |
|----------------------------------|------------------------------------------------------------------|
| 대규모 데이터 저장               | 안정 해시를 사용해 서버들에 부하 분산                          |
| 읽기 연산에 대한 높은 가용성 보장 | 데이터를 여러 데이터센터에 다중화                               |
| 쓰기 연산에 대한 높은 가용성 보장 | 버저닝 및 벡터 시계를 사용한 충돌 해소                         |
| 데이터 파티션                     | 안정 해시                                                        |
| 점진적 규모 확장성               | 안정 해시                                                        |
| 다양성(heterogeneity)            | 안정 해시                                                        |
| 조절 가능한 데이터 일관성        | 정족수 합의(quorum consensus)                                   |
| 일시적 장애 처리                 | 느슨한 정족수 프로토콜(sloppy quorum)과 단서 후 임시 위탁(hinted handoff) |
| 영구적 장애 처리                 | 머클 트리(Merkle tree)                                           |
| 데이터 센터 장애 대응            | 여러 데이터 센터에 걸친 데이터 다중화                           |