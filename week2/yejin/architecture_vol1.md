# 📒 1장 - 사용자 규모에 따른 확장성

### ✅ 단일서버

웹 - 앱 - 데이터베이스 - 캐시 등이 한 서버에서 동작

### ✅ 데이터베이스

웹/모바일 트래픽 처리용도의 서버(웹 계층)와 데이터베이스용 서버(데이터 계층)를 분리

- 독립적 확장 추구
- **비-관계형(NoSQL) 데이터베이스가 좋은 선택일 수 있는 경우**
    - 아주 낮은 응답 지연시간 필요
    - 다루는 데이터가 비정형 데이터인 경우
    - 데이터를 직렬화/역직렬화 할 수만 있으면 되는 경우
    - 아주 많은 양의 데이터를 저장할 필요가 있는 경우

### ✅ 수직적 규모 확장 / 수평적 규모 확장

스케일 업 / 스케일 아웃

- 수직적 규모 확장(스케일 업)은 장애에 대한 자동복구 방안이나 다중화 방안을 제시하지 않음

### ✅ **로드 밸런서**

- 부하 분산 집합에 속한 웹서버에게 트래픽 부하 고르게 분산
- 로드밸런서를 public ip로 두고 내부에선 private ip로 이용 → 보안 위함
- 자동복구 문제 해결 및 웹 계층 가용성 향상

### ✅ **데이터베이스 다중화**

- 서버 사이에 주 - 부 관계를 설정하고 데이터 원본은 주 서버에, 사본은 부 서버에 저장하는 방식
- 부 데이터베이스는 읽기 연산만을 지원 → 일반적으로 읽기 연산이 트래픽이 대다수이므로 주 데이터베이스보다 수가 많아야 함
- 주/부 데이터베이스 둘 다 정상인 경우 역할이 나뉘어져 있지만, 한 측의 데이터베이스가 사용 불가능하다면 다른 측의 데이터베이스가 다 커버하도록 설계됨

### ✅ 캐시

- 캐시계층:
    - 데이터가 잠시 보관되는 곳
    - 데이터 베이스보다 빠름 → 성능 개선, 데이터베이스 부화 줄임, 독립적 확장 가능
    
- 캐시 사용시 유의 할 점
    - 갱신은 자주 일어나지 않지만 참조 빈번할때
    - 어땬 데이터를?
        - 휘발성 메모리에 두므로, 영속적으로 보관할 데이터를 캐시에 두는 것은 바람직하지 않음
        - 캐시서버가 재시작시 데이터는 다 날아감
        - 즉 중요 데이터는 지속적 저장서에
    - 어떻게 만료?
        - 만료 정책
    - 일관성 유지
        - 데이터 원본과 캐시의 정보가 일치하는가
    - 장애 대처
        - 캐시 서버를 한대만 주는경우
            - 당일 장애 지점 가능성( 어떤 특정 지점에서의 장애가 전체 시스템의 동작을 중간시켜버릴 수 있는 경우) → 서버 분산 필요
    - 캐시 크기
    - 데이터 방출 정책
        - LRU
        - LFU
    
    ### ✅ CDN
    
    - 개념: 정적 콘텐츠를 전송하는데 쓰이는 지리적으로 분산된 서버의 네트워크
    - 동작 방법
        - 사용자가 웹사이트 방문 → 가까운 cdn 서버가 정적 콘텐츠 전딜
    - 고려해야할 사항
        - 비용
        - 적절한 만료 시한 설정
        - cdn 장애에 대한 대처 방안
        - 콘텐츠 무효화 방법

### ✅ 무상태 웹 계층

수평적으로 확장하는 밥 → 상태 정보를 웹계층에서 제거

강태 정보를 db에 저장히고 필요할때 불려오는 거

- 상태 웹사이트의 문제점: 같은 클라이언트는 같은 서버로 전송되어야하는 문제점
- 로드밸런서가 이 역할을 해주는데 주담으 주고, 로드 밸런서 뒷단에 서버를 추가하거나 제거ㅏ기 까다롭다.

### ✅ 데이터 센터

- 지리적 라우팅: 가장 가까운 데이터 센터로 안내 되는 것
- 다중 데티러센터 아키텍쳐 설계시 해결해야하는 기술적 난제
    - 트래픽 우회
    - 데이터 동기화
    - 테스트와 배포

### ✅ 메세지 큐

개념: 메세지의 무손실을 보장하는 비동기 통신을 지원하는 컴포넌트

메세지의 버퍼 역할을 하며 비동기적으로 전송

- 장점:
    - 서비스 또는 서버 간 결합이 느슨해져 규모 학장성이 보장

### ✅ 로그

- 에러 로그 관리 중요

### ✅ 매트릭

- 호스트 단위 매트릭: cpu, 메모리..
- 종합 매트릭: 데이터 베이스 계층의 성능, 캐시 계층의 성능
- 핵심 비즈니스 매트릭: 재방믄, 수익, 일별 능동 사용자

### ✅ 데이터베이스 규모 확장

1. 수직적 확장
    1. 고성능 자원 증설
    2. 문제점:
        1. 한계존제
        2. spof 발생 가능성
        3. 고비용
2. 수평적 확장(샤딩)
    1. 많은 서버 추가
    2. 데이터베이스를 샤드라는 작은 다위로 분할
    3. 모든 샤드는 같은 스키마를 사용하지만 샤드에 보관이 돠는 데이터 사이 중복 없음
    4. 고려해야할 점:
        1. 샤깅키를 어떻게 정하는지
        - 데이터의 재샤딩
        - 유명인사 문제(핫스핏 키 문제)
        - 조인과 비정규화

# 📒 4장 -  처리율 제한 장치의 설계

### ✅ 처리율 제한 장치

- 개념: 클라이언트 또는 서비스가 보내는 트레픽의 처리율을 제어하기 위한 장치
- 장점:
    1. dos 공격에 의한 자원 고갈 방지
    2. 비용 절감
    3. 서버 과부하를 막음

## 1️⃣ 1단계: 문제 이해 및 설계 범위 확정

## 2️⃣ 2단계: 개략적 설계안 제시 및 동의 구하기

- 처리율 제한 장치를 어디에 둘 것인가( 클라이언트 vs 서버)
    - 클라이언트는 일반적으로 안정적으로 처리율 제한을 두지 못함
    - 서버
        - api 서버에 두기
        - 처리율 제한 미들웨어 생성
        - → 어디에 두어야하나? 상황에 따라 다름
- 

### ✅ 처리율 제한 알고리즘
| 알고리즘 | 개념 및 원리 | 인자(Parameters) | 장점 | 단점 |
| --- | --- | --- | --- | --- |
| **토큰 버킷(Token Bucket)** | - 일정 용량을 가진 버킷에 토큰이 일정 속도로 채워짐<br>- 요청 처리 시 토큰을 1개 소모<br>- 토큰이 부족하면 요청을 거부 | - **버킷 크기**: 토큰 최대 개수<br>- **토큰 공급률**: 초당 생성되는 토큰 수 | - 구현 간단<br>- 메모리 효율적<br>- 짧은 시간 동안 몰리는 트래픽을 흡수하여 처리 가능 | - 적절한 버킷 크기 및 토큰 공급률 튜닝이 어려울 수 있음 |
| **누출 버킷(Leaky Bucket)** | - FIFO 큐 기반<br>- 큐가 가득 찼을 경우 새로운 요청은 폐기<br>- 고정된 속도로 요청을 처리 | - **버킷 크기**: 큐 사이즈<br>- **처리율**: 단위 시간당 처리 가능한 요청 수 | - 메모리 사용량 안정적<br>- 일정한 처리율이 필요할 때 적합 | - 단시간 급증 트래픽 처리 불리<br>- 오래된 요청이 남아 최신 요청이 손실될 수 있음<br>- 인자 설정이 까다로움 |
| **고정 윈도 카운터(Fixed Window Counter)** | - 타임라인을 고정된 구간으로 나눔<br>- 각 윈도마다 요청 수를 카운팅<br>- 임계치 초과 시 요청 거부 | - **윈도 크기**<br>- **임계치(Threshold)** | - 구현 간단<br>- 메모리 사용량 적음<br>- 특정 트래픽 패턴에 적합 | - 윈도 경계 문제로 짧은 시간에 많은 요청이 유입될 경우 허용량보다 더 많은 요청 허용 가능 |
| **이동 윈도 로깅(Sliding Window Log)** | - 각 요청의 타임스탬프를 저장하여 관리<br>- 허용 시간 범위를 벗어난 요청 기록 제거<br>- 로그 크기가 제한치 이하이면 요청 허용 | - **윈도 크기**<br>- **허용 요청 수** | - 처리율 제한이 매우 정밀함 | - 요청 기록을 저장해야 하므로 메모리 사용량이 많음 |
| **이중 윈도 카운터(Sliding Window Counter)** | - 고정 윈도 + 이동 윈도 방식 혼합<br>- 현재 구간과 직전 구간의 요청 수를 가중 합산하여 추정 | - **윈도 크기**<br>- **임계치(Threshold)** | - 갑작스런 트래픽 변화에 대응 가능<br>- 메모리 효율적 | - 정확도가 100%는 아님(추정치 기반)<br>- 하지만 실험상 오차는 매우 낮음(오탐 약 0.003%) |

### ✅  어디에 둘 것인가.

1. 레디스
    - INCR: 메모리에 저장된 카운터 값 +1
    - EXPIRE: 카운터에 타임아웃 값 설정

## 3️⃣ 3단계: 상세 설계

### ✅  처리율 제한 규칙

- 처리율 한도 초과 트래픽 처리
- HTTP 429 응답 (Too many requests): 어떤 요청이 한도 제한에 걸릴때 응답경우에 따라서 한도 제한에 걸린 메시지를 나중에 처리하기 위해 큐에 보관할 수 있음
- 처리율 제한 장치가 사용하는 HTTP 헤더클라이언트가 자기 요청이 처리율 제한에 걸리고 있는지에 대한 정보를 아래 HTTP 헤더를 통해 전달

| 헤더 | 의미 |
| --- | --- |
| `X-RateLimit-Remaining` | 현재 윈도 내에서 남은 요청 가능 횟수 |
| `X-RateLimit-Limit` | 해당 윈도 동안 허용되는 최대 요청 횟수 |
| `X-RateLimit-Retry-After` | 다시 요청하기까지 대기해야 하는 시간(초 단위) |

---

### ✅ **분산 환경에서의 처리율 제한 장치의 구현**

1. 경쟁 조건 (race condition)
    - **문재**
        - 경쟁 이슈가 발생하는 동작
    - **해결 방법**
        1. 레디스에서 카운터의 값을 읽음
        2. counter +1 의 값이 임계치를 넘는지 봄
        3. 넘지 않는다면 레디스에 보관된 카운터 값을 1만큼 증가시킴

1. 동기화 이슈
    - **문재**
        - 여러대의 처리율 제한 장치를 사용할 경우 요청이 분산될 수 있음
    - **해결 방법**
        - Sticky session 을 사용하여 같은 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있도록 할 수 있음
2. 성능 최적화
    - **문재**
        - 지연시간
    - **해결 방법**
        - 지연시간을 줄이기 위해 사용자의 트래픽을 가장 가까운 Edge 서버로 전달하여 지연시간을 줄임

1. 모니터링
    - 처리율 제한 장치를 설치 후 효과적으로 동작하는지 확인해야함

###