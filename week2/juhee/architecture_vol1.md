# 📘 대규모 시스템 설계 기초 - 1장 스터디 요약  
**챕터 1: 사용자 수에 따른 규모 확장성 (1~29p)**  

이 문서는 《대규모 시스템 설계 기초》 1장의 핵심 내용을 정리한 자료입니다.  
단일 서버 아키텍처에서 시작해 수백만 사용자를 지원하는 대규모 시스템으로 발전하는 과정의 기본 구성 요소를 다룹니다.

---

## 🖥️ 1. 단일 서버 (Single Server)

### 개요  
가장 단순한 시스템 형태로, 모든 구성 요소가 하나의 서버에 위치합니다.  
- 웹 애플리케이션  
- 데이터베이스  
- 캐시  

### 동작  
사용자의 요청은 서버의 공인 IP로 직접 전달되고, 서버가 모든 로직을 처리한 뒤 응답합니다.

### 한계점  
- **SPOF (Single Point of Failure)**: 서버 장애 시 전체 서비스 중단  
- **확장성 부족**: 트래픽 증가 시 서버 과부하 발생

---

## 💾 2. 데이터베이스 (Database) 분리

### 목적  
웹 서버와 데이터베이스 서버를 분리하여 **전문화** 및 **독립적 확장**을 가능하게 합니다.

### 이유  
- **웹/앱 서버**: CPU 중심  
- **데이터베이스 서버**: I/O 중심  

따라서 분리하면 각 서버의 리소스를 효율적으로 활용할 수 있습니다.

---

## ⚙️ 3. 수직적 vs 수평적 규모 확장

### 🧱 수직적 규모 확장 (Vertical Scaling / Scale Up)
- **방법**: 기존 서버의 하드웨어 성능 향상 (CPU, RAM 추가)
- **장점**: 구현이 간단함
- **단점**:
  - 물리적 한계 존재  
  - 비용 급증  
  - SPOF 해결 불가  

### 🌐 수평적 규모 확장 (Horizontal Scaling / Scale Out)
- **방법**: 여러 서버를 추가하여 부하 분산
- **장점**:
  - 이론상 무한 확장 가능  
  - 가용성과 안정성 향상  
- **단점**:
  - 아키텍처 복잡성 증가 (예: 로드밸런서 필요)

---

## ⚖️ 4. 로드밸런서 (Load Balancer)

### 역할  
여러 대의 웹 서버 앞단에 위치하여 요청을 균등하게 분배합니다.

### 주요 기능  
- **부하 분산**: 특정 서버에 트래픽 집중 방지  
- **Health Check**: 장애 서버 감지 및 요청 차단 → 서비스 가용성 보장  

---

## ⚡ 5. 캐시 (Cache)

### 개념  
자주 접근되거나 계산 비용이 큰 데이터를 메모리 기반 저장소(예: Redis, Memcached)에 임시 저장하여 빠르게 응답합니다.

### 동작 원리  
1. 클라이언트 요청  
2. 캐시에서 데이터 존재 여부 확인  
   - **Cache Hit**: 캐시에서 즉시 응답  
   - **Cache Miss**: DB에서 조회 후 캐시에 저장  

### 효과  
- 데이터베이스 부하 감소  
- 응답 속도 향상  

---

## 🌍 6. 콘텐츠 전송 네트워크 (CDN)

### 개념  
정적 콘텐츠(이미지, 동영상, CSS, JS 등)를 전 세계 **Edge 서버**에 저장하여 사용자에게 더 가까운 위치에서 전송합니다.

### 동작  
사용자가 정적 파일을 요청하면, CDN 서버가 해당 콘텐츠를 직접 전달합니다.

### 장점  
- 지연 시간(Latency) 최소화  
- 애플리케이션 서버의 부하 감소  

---

## 🧩 7. 무상태(Stateless) 웹 계층

### 유상태(Stateful) 아키텍처의 문제  
- 각 웹 서버가 세션 정보를 자체적으로 저장  
- 특정 서버에 종속 → 장애 시 세션 유실 발생  

### 무상태(Stateless) 아키텍처의 원칙  
- 서버는 사용자 상태를 저장하지 않음  
- **세션 정보는 외부 저장소(예: 캐시, DB)** 에 저장  

### 장점  
- 요청이 어떤 서버로 가든 동일하게 처리 가능  
- 장애 복원력 및 확장성 대폭 향상  

---

