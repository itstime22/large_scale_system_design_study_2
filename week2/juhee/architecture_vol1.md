# 📘 대규모 시스템 설계 기초 - 1장 스터디 요약  
**챕터 1: 사용자 수에 따른 규모 확장성 (1~29p)**  

이 문서는 《대규모 시스템 설계 기초》 1장의 핵심 내용을 정리한 자료입니다.  
단일 서버 아키텍처에서 시작해 수백만 사용자를 지원하는 대규모 시스템으로 발전하는 과정의 기본 구성 요소를 다룹니다.

---

## 1. 단일 서버 (Single Server)

### 개요  
가장 단순한 시스템 형태로, 모든 구성 요소가 하나의 서버에 위치합니다.  
- 웹 애플리케이션  
- 데이터베이스  
- 캐시  

### 동작  
사용자의 요청은 서버의 공인 IP로 직접 전달되고, 서버가 모든 로직을 처리한 뒤 응답합니다.

### 한계점  
- **SPOF (Single Point of Failure)**: 서버 장애 시 전체 서비스 중단  
- **확장성 부족**: 트래픽 증가 시 서버 과부하 발생

---

## 2. 데이터베이스 (Database) 분리

### 목적  
웹 서버와 데이터베이스 서버를 분리하여 **전문화** 및 **독립적 확장**을 가능하게 합니다.

### 이유  
- **웹/앱 서버**: CPU 중심  
- **데이터베이스 서버**: I/O 중심  

따라서 분리하면 각 서버의 리소스를 효율적으로 활용할 수 있습니다.

---

## 3. 수직적 vs 수평적 규모 확장

### 🧱 수직적 규모 확장 (Vertical Scaling / Scale Up)
- **방법**: 기존 서버의 하드웨어 성능 향상 (CPU, RAM 추가)
- **장점**: 구현이 간단함
- **단점**:
  - 물리적 한계 존재  
  - 비용 급증  
  - SPOF 해결 불가  

### 🌐 수평적 규모 확장 (Horizontal Scaling / Scale Out)
- **방법**: 여러 서버를 추가하여 부하 분산
- **장점**:
  - 이론상 무한 확장 가능  
  - 가용성과 안정성 향상  
- **단점**:
  - 아키텍처 복잡성 증가 (예: 로드밸런서 필요)

---

## 4. 로드밸런서 (Load Balancer)

### 역할  
여러 대의 웹 서버 앞단에 위치하여 요청을 균등하게 분배합니다.

### 주요 기능  
- **부하 분산**: 특정 서버에 트래픽 집중 방지  
- **Health Check**: 장애 서버 감지 및 요청 차단 → 서비스 가용성 보장  

---

## 5. 캐시 (Cache)

### 개념  
자주 접근되거나 계산 비용이 큰 데이터를 메모리 기반 저장소(예: Redis, Memcached)에 임시 저장하여 빠르게 응답합니다.

### 동작 원리  
1. 클라이언트 요청  
2. 캐시에서 데이터 존재 여부 확인  
   - **Cache Hit**: 캐시에서 즉시 응답  
   - **Cache Miss**: DB에서 조회 후 캐시에 저장  

### 효과  
- 데이터베이스 부하 감소  
- 응답 속도 향상  

---

## 6. 콘텐츠 전송 네트워크 (CDN)

### 개념  
정적 콘텐츠(이미지, 동영상, CSS, JS 등)를 전 세계 **Edge 서버**에 저장하여 사용자에게 더 가까운 위치에서 전송합니다.

### 동작  
사용자가 정적 파일을 요청하면, CDN 서버가 해당 콘텐츠를 직접 전달합니다.

### 장점  
- 지연 시간(Latency) 최소화  
- 애플리케이션 서버의 부하 감소  

---

## 7. 무상태(Stateless) 웹 계층

### 유상태(Stateful) 아키텍처의 문제  
- 각 웹 서버가 세션 정보를 자체적으로 저장  
- 특정 서버에 종속 → 장애 시 세션 유실 발생  

### 무상태(Stateless) 아키텍처의 원칙  
- 서버는 사용자 상태를 저장하지 않음  
- **세션 정보는 외부 저장소(예: 캐시, DB)** 에 저장  

### 장점  
- 요청이 어떤 서버로 가든 동일하게 처리 가능  
- 장애 복원력 및 확장성 대폭 향상

---

## 🏁 요약

| 구성 요소 | 주요 목적 | 장점 | 단점 |
|------------|------------|------|------|
| 단일 서버 | 초기 구조 | 단순함 | SPOF, 확장 한계 |
| DB 분리 | 역할 분리 | 효율적 자원 활용 | 구성 복잡도 증가 |
| 수직 확장 | 하드웨어 강화 | 간단한 구현 | 비용/한계 존재 |
| 수평 확장 | 서버 추가 | 무한 확장, 안정성 향상 | 복잡한 설계 |
| 로드밸런서 | 트래픽 분산 | 가용성 확보 | 관리 필요 |
| 캐시 | 응답 속도 향상 | 빠른 처리 | 데이터 동기화 필요 |
| CDN | 정적 콘텐츠 전송 최적화 | 지연 최소화 | 비용 발생 가능 |
| 무상태 웹 계층 | 확장성 확보 | 안정성 증가 | 외부 세션 관리 필요 |

---

# 📚 대규모 시스템 설계 기초 - 4장 스터디 요약  
**챕터 4: 처리율 제한 장치의 설계 (Rate Limiter)**  
(51p ~ 73p)

---

## 개요

**처리율 제한 장치(Rate Limiter)** 는 클라이언트나 서비스가 특정 기간 동안 보낼 수 있는 요청 수를 제어하는 시스템입니다.  
이는 시스템을 보호하고, 서비스 품질을 유지하며, 비용을 관리하는 데 필수적인 구성 요소입니다.

---

## 1. 처리율 제한 장치가 필요한 이유

- **DoS(Denial of Service) 공격 방지**: 악의적인 사용자가 대량의 트래픽을 유발해 시스템을 마비시키는 것을 방지  
- **비용 관리**: 요청 수에 비례해 과금되는 외부 API 사용 시 예산 초과 방지  
- **서버 과부하 방지**: 트래픽 급증(Spike) 시 서버가 감당 가능한 수준으로 요청을 조절  
- **공평한 자원 분배**: 특정 사용자가 API 자원을 독점하지 못하도록 제어  

---

## 2. 처리율 제한 장치의 구현 위치

| 구현 위치 | 설명 | 장단점 |
|------------|------|--------|
| **클라이언트 측** | 브라우저, 모바일 앱에서 구현 | 신뢰 불가 (조작 가능) |
| **서버 측** | 애플리케이션 내부 로직에서 구현 | 비교적 간단하지만, 트래픽 집중 시 부담 |
| **게이트웨이/미들웨어** | API 게이트웨이 또는 로드밸런서에서 구현 | ✅ **가장 권장되는 방식** (중앙 제어 가능) |

---

## 3. 주요 처리율 제한 알고리즘

시스템 설계 면접에서 자주 등장하는 대표적인 알고리즘 다섯 가지입니다.

---

### 1) 토큰 버킷 (Token Bucket)

- **개념**: 일정한 속도로 버킷에 토큰이 채워짐  
- **동작**:
  1. 요청 시 버킷의 토큰 존재 여부 확인  
  2. 토큰이 있으면 1개 소모하고 요청 처리  
  3. 토큰이 없으면 요청 거부(Drop)  
- **특징**:
  - **버스트(Burst) 트래픽 허용 가능**  
  - 예: 초당 10개 토큰 생성, 버킷 크기 100 → 순간 100개의 요청 가능

---

### 2) 누수 버킷 (Leaky Bucket)

- **개념**: 요청은 큐(Queue)에 저장되고, 일정한 속도로 처리됨  
- **동작**:
  - 큐가 가득 차면 새로운 요청은 거부  
  - “물통에 물을 붓고 일정 속도로 새어 나가는” 형태  
- **특징**:
  - 요청을 **균등하게 처리(Smoothing)**  
  - 버스트 트래픽은 허용하지 않음

---

### 3) 고정 윈도 카운터 (Fixed Window Counter)

- **개념**: 일정 시간 단위(Window)마다 요청 수를 카운팅  
- **동작**:
  - 예: 1분 동안 100개의 요청 제한  
  - 현재 윈도우 카운터가 한도 초과 시 요청 거부  
- **단점**:
  - **윈도우 경계 문제(Edge Burst)** 발생  
  - 예: 1:00:59에 100개 + 1:01:01에 100개 → 2초 동안 200개 처리

---

### 4) 슬라이딩 윈도 로그 (Sliding Window Log)

- **개념**: 모든 요청의 타임스탬프를 로그(예: Redis Sorted Set)에 저장  
- **동작**:
  1. 새 요청이 오면 “현재시간 - 윈도우 크기” 이후의 요청 로그를 계산  
  2. 요청 수가 한도를 넘으면 거부  
- **특징**:
  - 정확도가 높지만 **메모리 사용량이 많음**

---

### 5) 슬라이딩 윈도 카운터 (Sliding Window Counter)

- **개념**: 고정 윈도 카운터 + 슬라이딩 윈도 로그의 절충안  
- **동작**:
  - 현재 윈도우와 이전 윈도우의 카운트를 **가중 평균**으로 계산  
  - 예: `(이전 윈도 카운트 * 경과비율) + (현재 윈도 카운트)`  
- **특징**:
  - **정확성과 효율성의 균형**  
  - 실제 서비스에서 가장 자주 사용됨

---

## 4. 분산 환경에서의 처리율 제한

분산 시스템에서는 서버마다 별도 카운터를 가지면 안 됩니다.  
(예: 10대 서버 × 100개 제한 → 총 1,000개 허용되는 문제 발생)

### ✅ 해결책: 중앙 집중식 저장소 사용
- **Redis**  
  - In-memory 기반의 빠른 데이터 저장소  
  - `INCR` 연산이 **원자적(Atomic)** 으로 수행되어 Race Condition 방지  
  - 카운터 키에 `EXPIRE` 설정하여 윈도우 시간 자동 만료  

---

## 5. 시스템 설계 요약

### 구성 요소
- **정책(Policy)**:  
  - 제한 규칙 (예: 사용자당 분당 20회, IP당 초당 10회)  
  - 별도의 DB에 저장  

- **중앙 저장소**:  
  - Redis를 사용하여 요청 카운트를 원자적으로 관리  

### 동작 흐름
1. 요청이 **API 게이트웨이**에 도달  
2. 게이트웨이가 Redis에서 요청 카운터 확인  
3. 한도 미만 → `INCR` 후 백엔드 서버로 전달  
4. 한도 초과 → **HTTP 429 (Too Many Requests)** 반환  

### 응답 헤더 예시
| 헤더 | 설명 |
|------|------|
| `Retry-After` | 재시도까지 남은 시간 (초 단위) |
| `X-RateLimit-Remaining` | 남은 요청 수 |
| `X-RateLimit-Reset` | 제한이 초기화되는 시각 |

---

## 🏁 요약

| 알고리즘 | 특징 | 장점 | 단점 |
|-----------|------|------|------|
| **토큰 버킷** | 일정 속도 + 버스트 허용 | 유연함, 속도 빠름 | 구현 복잡 |
| **누수 버킷** | 균일한 처리율 | 안정적, 부하 완화 | 버스트 불가 |
| **고정 윈도 카운터** | 단순 카운팅 | 구현 용이 | 경계 문제 발생 |
| **슬라이딩 윈도 로그** | 정확한 계산 | 정확도 높음 | 메모리 부담 |
| **슬라이딩 윈도 카운터** | 가중 평균 | 정확도/성능 균형 | 약간의 근사치 발생 |

---

📖 **핵심 요약**
> 처리율 제한은 서비스 안정성과 비용 절감을 위해 반드시 필요한 설계 요소이다.  
> 실제 구현에서는 Redis 기반의 중앙 카운터와 슬라이딩 윈도 카운터 방식이 가장 실용적이다.
