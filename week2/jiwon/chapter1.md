# 1장

1. 단일서버
2. 여러개의 서버

사용자가 늘 경우, 여러개의 서버를 두어야 한다.

데이터 베이스의 종류에는

1. 관계형 데이터베이스 관리 시스템(relational Data-base Management System, RDBMS)

ex) mysql, Oracle, PostgreSQL…

1. 비 관계형 데이터베이스

가 있다.

보통의 경우 관계형 데이터베이스가 최선이지만, 이런 경우에는 비 관계형 데이터베이스가 바람직한 선택

- 아주 낮은 지연 응답시간
- 다루는 데이터가 비정형일 경우
- 데이터를 직렬화하거나 역직렬화 할 수 있기만 하면 될 경우
- 아주 많은 양의 데이터를 저장할 필요가 있을 경우

## 데이터베이스의 규모 확장

![image.png](attachment:97c2a0c1-91f1-497a-8b49-3fedc44bc685:image.png)

### 수직적 규모 확장 (scale-up)

> 서버에 고사양 자원 (더 좋은 CPU, 더 많은 RAM 등등)을 추가하는 행위이다.
>

수직적 규모 확장은 일단 한대의 서버에 cpu나 메모리를 무한대로 증설할 수는 없기 때문에, 서버 장애가 발생하면 완전히 중단되게 된다.

또한 사용자가 많아진다면 문제가 발생할 수 있다.

### 수평적 규모 확장 (Shading)

> 대규모 데이터베이스를 샤드라고 부르는 작은 단위로 분할하는 기술이다.
>

![image.png](attachment:a1d1794c-b08b-4adc-ab94-958252f2b6ce:image.png)

샤딩 전략을 구현할 때 고려해야 할 가장 중요한 것은 샤딩 키를 어떻게 정하느냐 하는 것이다.

- 데이터의 재 샤딩(resharding) : 재 샤딩은 다음과 같은 경우에 필요하다.
    - 데이터가 너무 많아져서 하나의 샤드로는 더 이상 감당하기 어려울 때
    - 샤드 간의 데이터 분포가 균등하지 못하여 어떤 샤드에 할당된 공간 소모가 다른 샤드에 비해 빨리 진행될 때이 경우를 샤드 소진(shard exhaustion)이라고도 부르는데 이런 현상이 발생하면 하고 하여야 한다. 안정 해시(consistent hashing) 기법을 활용하면 이 문제를 해결할 수 있다.
- 유명인사(celebrity) 문제 : 핫스팟 키(hotspot key) 문제라고도 부르는데, 특정 샤드에 질의가 집중되어 서버에 과부하가 걸리는 문제이다.다
- 조인과 비정규화(join and de-normalization) : 일단 하나의 데이터베이스를 여러 샤드 서버로 쪼개고 나면, 여러 샤드에 걸친 데이터를 조인하기가 힘들어진다. 이를 해결하는 한 가지 방법은 데이터베이스를 비정규화하여 하나의 테이블에서 질의가 수행될 수 있도록 하는 것이다.

### 로드밸런서

> 부하 분산 집합에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할
>

![로드밸런서.png](attachment:c6f8f770-6965-470c-9932-8e6cb2bfefe1:로드밸런서.png)

사용자 → 로드밸런서의 공개 ip 주소로 접속힌다.

웹 서버가 직접 접속 처리 X !

로드밸런서는 웹 서버와 통신하기 위해 사설 IP 주소를 이용한다.

### 데이터베이스 다중화

> 서버 사이에 주-부 관계를 설정하고 데이터의 원본은 주 서버에, 사본은 부 서버에 저장하는 방식이다.
>

**주 데이터베이스**: 쓰기 연산, 데이터베이스 변경 명령어 실행

**부 데이터베이스**: 읽기 연산

병렬로 처리되므로 성능이 좋아진다.

### 캐시

> 캐시는 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고, 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소이다.
>

- 캐시는 휘발성 메모리 이므로, 중요한 데이터는 지속석 저장소에 두어야 한다.
- 캐시 서버를 여러개로 분산시켜 단일 장애 지점이 생기는 문제를 해결할 수 있다.
- 캐시 메모리를 과할당하여, 캐시의 성능을 개선시킬 수 있다.
- 캐시에 메모리가 가득 찼을 경우, LRU나 LFU, FIFO 정책을 사용한다.

### CDN

> CDN은 정적 콘텐츠를 전송하는데 쓰이는, 지리적으로 분산된 서버의 네트워크이다.
>

<aside>

CDN의 동작 과정

1. 사용자가 image URL을 이용해 image.png에 접근한다.
2. CDN 서버의 캐시에 이미지가 없는 경우 서버는 원본 서버에 요청하여 파일을 가져온다.
3. 원본 서버가 파일을 CDN 서버에 반환한다.
4. CDN 서버는 파일을 캐시하고 사용자에게 반환한다.
</aside>

→ 정적 컨텐츠를 웹서버가 아닌 CDN을 사용하여 더 나은 성능을 보장할 수 있다.

캐시를 사용하여 데이터베이스 부하를 줄일 수 있다.

### 무상태 웹 계층

상태정보를 보관하는 서버는 클라이언트 정보(상태)를 유지하여 요청들 사이에 공유되도록 하지만, 무상태 서버에는 이런 장치가 없다.

상태 서버의 경우 같은 클라이언트로부터의 요청은 항상 같은 서버로 전송되어야 하는데, 이는 로드밸런서에 부담을 주게 된다.

아래 그림은 무상태 아키텍처를 나타낸다.

![image.png](attachment:e6633984-8908-4bdb-80b2-c4be1bd7a79a:image.png)

> 상태 정보는 웹서버로부터 물리적으로 분산되어있다.
>

이런 구조는 단순하고, 안정적이며, 규모 확장이 쉽다.

### 데이터 센터

장애가 없는 상황에서 사용자는 가장 가까운 데이터 센터로 안내되는데, 통상 이 절차를 지리적 라우팅이라고 부른다.

![image.png](attachment:80254bd4-2e71-4b00-84ba-ef125dd31353:image.png)

이 데이터 센터중 하나에 심각한 장애가 발생하면 모든 트래픽은 장애가 없는 데이터 센터로 전송된다.

다중 데이터센터를 만들기 위해 고려해야 할 조건

- 트래픽 우회 - 올바른 데이터 센터로 트래픽을 보내기
- 데이터 동기화 - 데이터 센터마다 별도의 데이터베이스 다중화 하기
- 테스트와 배포 - 여러 위치에서 애플리케이션 테스트, 자동화 배포가 모든 데이터 센터에 동일하게 설치되도록 하기

### 메세지 큐

> 메세지 큐에 일단 보관된 메시지는 소비가자 꺼낼때까지 안전히 보관된다는 특성을 보장하는 비동기 통신 컴포넌트
>
- 메세지 큐를 이용하면 서비스 또는 서버 간 결합이 느슨해져서, 규모 확장성이 보장되어야 하는 안정적 애플리케이션을 구성하기 좋다.
- Publish/Producer는 메세지 큐에 발행한다. 큐에는 보통 Consumer/Subscribe가 메세지를 꺼내서 동작을 수행한다.

## 정리

- 웹 계층은 무상태 계층으로
- 모든 계층에 다중화 도입
- 가능한 한 많은 데이터 캐시
- 여러 데이터센터 지원
- 정적 컨텐츠 → CDN 통해 서비스
- 데이터 계층 → 샤딩을 통해 그 규모를 확장할 것
- 각 계층은 독립적 서비스로 분한
- 자동화 도구 활용, 시스템 지속적 모니터링

---


# 4장


처리율 제한 장치를 통해 자원 고갈을 방지하고, Dos 공격을 방지할 수 있다.

## 1단계 : 문제 이해 및 설계 범위 확장

### 요구사항

- 설정된 처리율을 초과하는 요청은 정확하게 제한한다.
- 처리율 제한 장치는 HTTP 응답시간에 나쁜 영향을 주어서는 안된다.
- 적은 메모리를 사용해야 한다.
- 하나의 처리율 제한 장치를 여러 서버나 프로세스에 공유할 수 있어야 한다.
- 요청이 제한되었을 때는 그 사실을 사용자에게 분명하게 보여주어야 한다.
- 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어서는 안 된다.

## 2단계 : 개략적 설계안 제시 및 동의 구하기

### 처리율 장치의 위치

1. 클라이언트 측 : 쉽게 위변조가 가능해 추천 X
2. 서버 측
3. 미들웨어 측

→ 기술 스택, 엔지니어링 인력, 우선순위에 따라 달라지게 된다/

### 처리율 제한 알고리즘

- 토큰 버킷
- 누출 버킷
- 고정 윈도 카운터
- 이동 윈도 로그
- 이동 윈도 카운터

### 토큰 버킷 알고리즘

> 저장된 용량을 갖는 컨테이너로, 사전 설정된 양의 토큰이 주기적으로 채워진다.
>
- 각 요청은 처리될 때마다 하나의 토큰을 사용한다.
- 토큰이 있는 경우, 버킷에서 토큰 하나를 꺼낸 후 요청을 시스템에 전달한다.
- 토큰이 없는 경우, 해당 요청은 버려진다.
- API 엔드포인트마다 별도의 버킷을 둔다.

이해가 쉬운 예시 : 사용자마다 하루에 포스팅 제한, 친구 추가 제한, 좋아요 개수 제한이 이있다면 사용자마다 3개의 버킷을 두어야 한다.

![image.png](attachment:b9583157-0cac-48a3-b293-96a5a27b7174:image.png)

**장점**

- 구현이 쉬움
- 메모리 효율적
- 짧은 시간에 집중 되는 트래픽도 잘 처리

**단점**

- 버킷 크기 & 토큰 공급률 두 개의 인자를 필요로하는 알고리즘이기 때문에 적절하게 튜닝하는 것이 어렵다.

### 누출 버킷 알고리즘

- 토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정되어 있다는 점이 다르다.
- 보통 FIFO 큐로 구현한다.

**장점**

- 큐의 크기 제한 -> 메모리 효율적 사용
- 고정된 처리율을 가지고 있어 안정적 출력 (stable outflow rate) 이 필요한 경우 적합

**단점**

- 단기간에 많은 트래픽이 몰리는 경우 최신 요청들이 버려지게 될 수 있음
- 토큰 버킷 알고리즘처럼 튜닝이 어렵다. (버킷 크기 & 처리율)

### 고정 윈도 카운터 알고리즘

> 타임라인을 고정된 간격의 window로 나눠 각 윈도우마다 카운터를 붙이고 요청이 접수되면 1씩 증가시킨다. 카운터가 임계치에 도달하면 새로운 요청은 버려진다.
>

**장점**

- 메모리 효율이 좋다.
- 이해하기 쉽다.
- Window 가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다.

**단점**

- Window 경계 부근에 트래픽이 몰리면 설정한 임게치를 초과할 수 있다.

### 이동 윈도 로깅 알고리즘

> 요청의 타임스탬프를 추정하여 고정윈도 카운터 알고리즘의 문제를 해결한다.
>
- 요청의 타임 스탬프를 redis나 정렬 집합 같은 캐시에 보관한다.
- 새 요청이 오면 만료된 타임스탬프는 제거한다.
- 로고의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다.

![image.png](attachment:f270d30b-a098-4695-b0ed-6d314984155f:image.png)

**장점**

- 처리율 제한 메커니즘이 매우 정교하다.
- 어느 순간의 윈도를 보더라도 처리율 한도를 넘지 않는다.

**단점**

- 거부된 요청의 타임스탬프도 보관하기 때문에 메모리를 많이 사용한다.

### 이동 윈도 카운터 알고리즘

> 고정 윈도 카운터 알고리즘과 이동 윈도 로깅 알고리즘을 결합하였다.
>

• 현재 1분간의 요청 수 + 직전 1분간의 요청 수 x 이동 윈도와 직전 1분이 겹치는 비율

**장점**

- 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽 대응에 용이하다.
- 메모리 효율이 좋다.

**단점**

- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 떄문에 100% 정확하지는 않다.

## 3단계 : 상세 설계

### 분산 환경에서의 처리율 제한 장치의 구현

여러개의 서버와 병렬 스레드를 지원하도록 시스템을 확장할 경우, 두가지 어려운 문제를 해결해야 한다.

- 경쟁 조건
- 동기화

### 경쟁 조건

처리율 제한 장치는 대략 다음과 같이 동작한다.

- 레디스에서 카운터의 값을 읽음(counter)
- `counter + 1`의 값이 임계치를 넘는지 확인
- 넘지 않는다면 레디스에 보관된 카운터 값을 1만큼 증가
- 병행성이 심한 환경에서는 `경쟁 조건 이슈`가 발생할 수 있다.

경쟁 조건 문제는 락으로 해결할 수 있다. 그러나 락은 시스템의 성능을 상당히 떨어뜨린다는 문제가 있다.

위 설계의 경우 락 대신 쓸 수 있는 해결책이 두 가지 있다.

- 루아 스크립트
- 정렬 집합이라 불리는 레디스 자료구조를 쓰는 것

### 동기화 이슈

![image.png](attachment:8f1ca8a6-e71a-4421-83e2-d79b96dc3a67:image.png)

왼쪽 그림의 경우 클라이언트 1은 제한 장치 1에 요청을 보내고 클라이언트 2는 제한 장치 2에 요청을 보내고 있다.

웹 계층은 무상태(stateless)이므로 클라이언트는 다음 요청을 그림 4-15의 오른쪽 그림처럼 각기 다른 제한 장치로 보낼 수 있다.

이때 동기화를 하지 않는다면, 제한 장치 1은 클라이언트 2에 대해서는 아무것도 모르기 때문에 처리율 제한을 올바르게 수행할 수 없을 것이다.

### 🚫 잘못된 해결책: 고정 세션 (Sticky Session)

- 같은 클라이언트의 요청을 항상 같은 서버로 보냄
- 하지만 서버 확장 시 유연성이 떨어지고, 부하 분산 효율이 낮음

### ✅ 권장 해결책: 중앙 집중형 저장소 사용

- **Redis** 같은 중앙 저장소에 요청 카운트를 저장
- 모든 서버가 공통된 데이터에 접근하므로

  **일관된 요청 제한(Throttle) 처리**가 가능함


### **💭 성능 최적화**

지금까지 살펴본 설계는 두 가지 지점에서 개선이 가능하다.

1. 여러 데이터센터 지원

여러 데이터센터를 지원하는 문제는 처리율 제한 장치에 매우 중요한 문제다.

데이터센터에서 멀리 떨어진 사용자를 지원하려다보면 지연시간이 증가할 수 밖에 없기 때문이다.

2. 제한 장치 간 데이터 동기화 시 최종 일관성 모델을 사용

### **💭 모니터링**

처리율 제한 장치를 설치한 이후에는 효과적으로 동작하고 있는지 보기위해 데이터를 모을 필요가 있다.

모니터링을 통해 다음 두 가지를 확인해야 한다.

- 채택된 처리율 제한 알고리즘이 효과적이다.
- 정의한 처리율 제한 규칙이 효과적이다.